<!DOCTYPE html>
<html lang="en">
 <head>
  <title>Response to HUD and Meta</title>
  <style>
   body { background: darkslateblue; }
   h1 { background: darkslateblue; color: lavenderblush; font-weight: bold; }
  </style>
  <style type="text/css" media="print">
   a {background: white; color: black}
   </style>
 </head>
 <body>
  <h1 style="font-weight:bold;font-size:larger;text-align:center; color:lavenderblush">
   The DOJ is Wrong
  </h1>
  <p>
    The two readings described the (somewhat) recent decision by the Department of Justice (from a Department of Human and Urban Development lawsuit) to require Meta on its Facebook platforms that deliver housing advertisements to terminate their algorithms. The DOJ came from the standpoint that the algorithms relied upon classification of a person that are protected under the FHA, like zip code, race, familial status and disability. They even go as far as to say that Meta “encouraged” housing discrimination. Now, some of the classifiers offered to advertisers on this platform seem to be somewhat broad or nonspecific to actual housing factors, like “interested in Hispanic culture” or “non-Christian”. In the end, this decision boils down to whether trained algorithms can be discriminatory. The DOJ came to the conclusion that they were. <strong>However, it is of my opinion that if this counts as discrimination, so too does all personalized job boards or targeted college recommendations.</strong>
  </p>
  <p style="color:lavenderblush">
    To begin, machine learning algorithms are based upon discrimination. Classifying individuals based on known (or assumed) external factors is the job of an algorithm in order to find patterns, and classification and discrimination can be synonyms in this instance. These demographic variables are factors that are collected on a number of sites as user information and are often listed in Terms of Service agreements with which users comply when beginning a service, like using Facebook. Advertisers exist on most places on the internet now, most of whom use targeted ad services to both a) have a better chance of a consumer purchasing the given product and b) give the consumer more relevant advertisements. Without an ad block, these targeted ads are often unable to be turned off as a user. It appears that the way Meta is offering targeted ad opportunities for a different form of business (<i>realty</i>) is no different from other target advertisement services that use similar demographic information (e.g. location, race).
  </p>
  <p style="color:lavenderblush">
    Now, it may be that HUD (and the DOJ) believed this was a different case in how the protected classes are being treated because it relates to <i>housing</i>. However, I am of the belief that access to education (which was determined to not be allowed to use racial features in its admissions process) and access to employment are similarly - and in the case of employment, perhaps <strong><i>more</i></strong> - protected under the law. In the case of employment, a parallel algorithm is used to take personal information of the user and send recommendations for jobs that match profiles, which includes classifying (<i>discriminating</i>) information like current location/zip code - a factor explicitly listed in the case of Meta that was discriminatory. If an individual is not sent recommended job posts due to these factors, under the same logic, that should be considered as discriminatory as not receiving a targeted ad for housing listings. Furthermore, various websites frequently send college/university recommendations based on a number of factors in their algorithm, likely including zip codes, race and gender.
  </p>
  <p style="color:lavenderblush">
    While I am on the side of nondiscrimination and fair treatment, the argument made here against Facebook’s targeted ad services is not unique to this one case and in fact spreads far beyond the cases here. The argument itself is essentially against any type of machine learning algorithm used for personalization/targeting. If that is their argument, then that can be their consistent argument and the DOJ should pursue lawsuits against most websites and companies on those grounds. In fact, they should remove all algorithms that provide recommendations, because most of its classifiers will be inherently discriminatory (under the legal definition as well as more colloquially). Rather, this case seems to come more in the wake of various legal departments across the globe having a reaction to new technology and services online and making war against technology companies, instead of examining some other more social factors playing into these issues. Certainly, there are issues with the behavior of technology companies and they are absolutely liable to scrutiny on their practices. <strong>However</strong>, the arguments governments and federal agencies are having against these companies do not seem entirely well-informed or focused on the actual outcomes of their decisions.
  </p>
 </body>
